{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is the main notebook.\n",
    "the supervised ML part of the project is all here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m TruncatedSVD\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompose\u001b[39;00m \u001b[39mimport\u001b[39;00m ColumnTransformer\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m wordnet, stopwords\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstem\u001b[39;00m \u001b[39mimport\u001b[39;00m WordNetLemmatizer\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleImputer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1871339da28c50be</td>\n",
       "      <td>cognizance@iitr.ac.in</td>\n",
       "      <td>students-notices@iitr.ac.in,staff-notices@iitr...</td>\n",
       "      <td>Cognizance 2023 is Live Now - Join the Excitem...</td>\n",
       "      <td>Greetings everyone,We are excited to announce ...</td>\n",
       "      <td>UNREAD,IMPORTANT,CATEGORY_PERSONAL,INBOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187129b4701da92f</td>\n",
       "      <td>dosw@iitr.ac.in</td>\n",
       "      <td>students-notices@iitr.ac.in</td>\n",
       "      <td>Opportunity to the Researchers to write techni...</td>\n",
       "      <td>Dear Students, Following is the link to the ab...</td>\n",
       "      <td>IMPORTANT,CATEGORY_PERSONAL,INBOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871298cfa0ea9df</td>\n",
       "      <td>dosw@iitr.ac.in</td>\n",
       "      <td>students-notices@iitr.ac.in</td>\n",
       "      <td>Advisory to reach your Bhawan by 1 am on March...</td>\n",
       "      <td>Dear Students, As you are aware, there are man...</td>\n",
       "      <td>UNREAD,IMPORTANT,Label_9,CATEGORY_PERSONAL,INBOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1871203b08c898ff</td>\n",
       "      <td>gensec.cult@iitr.ac.in</td>\n",
       "      <td>students-notices@iitr.ac.in</td>\n",
       "      <td>Annual Art Exhibition - \"दर्पण\" | Fine Arts | ...</td>\n",
       "      <td>Greetings!Fine Arts Section, IIT Roorkee is re...</td>\n",
       "      <td>IMPORTANT,Label_7,CATEGORY_PERSONAL,INBOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18711da44ef7c918</td>\n",
       "      <td>ccf@iitr.ac.in</td>\n",
       "      <td>students-notices@iitr.ac.in,staff-notices@iitr...</td>\n",
       "      <td>CCF stall with fun games and merchandise in AB...</td>\n",
       "      <td>Dear Campus CommunityCommittee for Campus Faun...</td>\n",
       "      <td>UNREAD,IMPORTANT,CATEGORY_PERSONAL,INBOX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                  sender  \\\n",
       "0  1871339da28c50be   cognizance@iitr.ac.in   \n",
       "1  187129b4701da92f         dosw@iitr.ac.in   \n",
       "2  1871298cfa0ea9df         dosw@iitr.ac.in   \n",
       "3  1871203b08c898ff  gensec.cult@iitr.ac.in   \n",
       "4  18711da44ef7c918          ccf@iitr.ac.in   \n",
       "\n",
       "                                            receiver  \\\n",
       "0  students-notices@iitr.ac.in,staff-notices@iitr...   \n",
       "1                        students-notices@iitr.ac.in   \n",
       "2                        students-notices@iitr.ac.in   \n",
       "3                        students-notices@iitr.ac.in   \n",
       "4  students-notices@iitr.ac.in,staff-notices@iitr...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  Cognizance 2023 is Live Now - Join the Excitem...   \n",
       "1  Opportunity to the Researchers to write techni...   \n",
       "2  Advisory to reach your Bhawan by 1 am on March...   \n",
       "3  Annual Art Exhibition - \"दर्पण\" | Fine Arts | ...   \n",
       "4  CCF stall with fun games and merchandise in AB...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Greetings everyone,We are excited to announce ...   \n",
       "1  Dear Students, Following is the link to the ab...   \n",
       "2  Dear Students, As you are aware, there are man...   \n",
       "3  Greetings!Fine Arts Section, IIT Roorkee is re...   \n",
       "4  Dear Campus CommunityCommittee for Campus Faun...   \n",
       "\n",
       "                                             labels  \n",
       "0          UNREAD,IMPORTANT,CATEGORY_PERSONAL,INBOX  \n",
       "1                 IMPORTANT,CATEGORY_PERSONAL,INBOX  \n",
       "2  UNREAD,IMPORTANT,Label_9,CATEGORY_PERSONAL,INBOX  \n",
       "3         IMPORTANT,Label_7,CATEGORY_PERSONAL,INBOX  \n",
       "4          UNREAD,IMPORTANT,CATEGORY_PERSONAL,INBOX  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails_df = pd.read_csv(\"../data/training_data.csv\", sep='~', index_col=0)\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
    "mails_df = pd.DataFrame(imputer.fit_transform(mails_df), columns=mails_df.columns)\n",
    "mails_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    processed_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def preprocess_sender(address):\n",
    "    address_lst = address.lower().split('@')\n",
    "    address_lst[1] = re.sub('[.]ac|[.]in|[.]com', '', address_lst[1])\n",
    "    address_lst[1] = re.sub('[.]', ' ', address_lst[1])\n",
    "    address_lst[0] = re.sub('[._]', '', address_lst[0])\n",
    "    return ' '.join(address_lst)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('subject', TfidfVectorizer(preprocessor=preprocess_text, max_df=0.9, min_df=0.005), 'subject'),\n",
    "    ('body', TfidfVectorizer(preprocessor=preprocess_text, max_df=0.8, min_df=0.01), 'body'),\n",
    "    ('sender', TfidfVectorizer(preprocessor=preprocess_sender), 'sender')\n",
    "],\n",
    "    # transformer_weights={\n",
    "    #     'subject': 2,\n",
    "    #     'body': 1,\n",
    "    #     'sender': 4\n",
    "    # },\n",
    "    remainder='drop')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('svd', TruncatedSVD(n_components=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "\n",
    "with open('../data/label_dict.json', 'r') as file:\n",
    "    all_labels = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:895: UserWarning: unknown class(es) ['CATEGORY_FORUMS', 'CATEGORY_PERSONAL', 'CATEGORY_PROMOTIONS', 'CATEGORY_UPDATES', 'IMPORTANT', 'INBOX', 'SENT', 'STARRED', 'UNREAD'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "label_list = [key for key in all_labels.keys() if re.match('Label_[0-9]', key)]\n",
    "mlb = MultiLabelBinarizer(classes=label_list)\n",
    "labels_array = [list(st.split(',')) for st in mails_df['labels']]\n",
    "mlb.fit(label_list)\n",
    "labels = mlb.transform(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix = pipeline.fit_transform(mails_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = mails_df\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 6) \n",
      "\n",
      "(360, 6) \n",
      "\n",
      "(838, 21) \n",
      "\n",
      "(360, 21) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lst = [X_train, X_test, y_train, y_test]\n",
    "for i in lst:\n",
    "    print(i.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "My main metric for evaluation is precision_score. It is best suited for the multi-output classification. Its details as mentioned in its documentation\n",
    "\n",
    "\n",
    "> Compute the precision.\n",
    "> The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    ">The best value is 1 and the worst value is 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "as sizes of all labels are different, and they are very imbalanced, so I've used average='weighted'\n",
    "\n",
    "> Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "models = [\n",
    "    ('DTree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('ETree', ExtraTreeClassifier(random_state=42)),\n",
    "    ('ETrees', ExtraTreesClassifier(random_state=42)),\n",
    "    ('RF', RandomForestClassifier(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('SVM', MultiOutputClassifier(SVC(random_state=42), n_jobs=-1)),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    # ('GaussianNB', GaussianNB()),\n",
    "    # ('MultinomialNB', MultinomialNB())\n",
    "]\n",
    "\n",
    "def try_different_models(models):\n",
    "    dfs = []\n",
    "    for name, model in models:\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred_on_train = clf.predict(X_train)\n",
    "\n",
    "        score = pd.Series(\n",
    "            [\n",
    "                accuracy_score(y_test, y_pred), accuracy_score(y_train, y_pred_on_train),\n",
    "                precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                precision_score(y_train, y_pred_on_train, average='weighted', zero_division=0)\n",
    "            ],\n",
    "            index=['test_accuracy', 'train_accuracy', 'precision_score'],\n",
    "            name=name\n",
    "        )\n",
    "        dfs.append(score)\n",
    "\n",
    "    print('shape of dataset: ', X.shape, y.shape)\n",
    "    print(pd.DataFrame(dfs))\n",
    "\n",
    "\n",
    "# try_different_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "SVM seems to be the best classifier among these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tuning hyperparameters using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recreating the pipeline for grid search\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('subject', TfidfVectorizer(preprocessor=preprocess_text), 'subject'),\n",
    "    ('body', TfidfVectorizer(preprocessor=preprocess_text), 'body'),\n",
    "    ('sender', TfidfVectorizer(preprocessor=preprocess_sender), 'sender')\n",
    "],\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "48 fits failed out of a total of 96.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\multioutput.py\", line 450, in fit\n",
      "    super().fit(X, Y, sample_weight, **fit_params)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\multioutput.py\", line 216, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\joblib\\parallel.py\", line 1061, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\joblib\\parallel.py\", line 938, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "    raise self._value\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\multioutput.py\", line 49, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 201, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 749, in _validate_targets\n",
      "    raise ValueError(\n",
      "ValueError: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 86.909s\n",
      "best score: nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'preprocessor__subject__max_df': [0.8, 0.9],\n",
    "        'preprocessor__subject__min_df': [0.005, 0.001],\n",
    "        'preprocessor__body__max_df': [0.8, 0.9],\n",
    "        'preprocessor__body__min_df': [0.05, 0.01],\n",
    "        'model__estimator__C': [0.01, 1, 100],\n",
    "        'model__estimator__kernel': ['rbf']\n",
    "    },\n",
    "    # {\n",
    "    #     'model_estimator__C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "    #     'model_estimator__kernel': ['rbf'],\n",
    "    #     'model_estimator__gamma': [0.1, 0.01, 0.001, 0.0001, 'scale'],\n",
    "    #     'model_estimator__class_weight': ['balanced', None]\n",
    "    # },\n",
    "    # {\n",
    "    #     'model_estimator__C': [0.01, 1, 100, 1000],\n",
    "    #     'model_estimator__kernel': ['linear', 'poly', 'sigmoid'],\n",
    "    #     'model_estimator__class_weight': ['balanced', None]\n",
    "    # }\n",
    "]\n",
    "\n",
    "model = MultiOutputClassifier(SVC(random_state=42), n_jobs=-1)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('svd', TruncatedSVD()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    cv=2,\n",
    "    scoring='precision',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t0 = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Done in {time() - t0:.3f}s\")\n",
    "print(f'best score: {grid_search.best_score_:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__estimator__C': 0.01,\n",
       " 'model__estimator__kernel': 'rbf',\n",
       " 'preprocessor__body__max_df': 0.8,\n",
       " 'preprocessor__body__min_df': 0.05,\n",
       " 'preprocessor__subject__max_df': 0.8,\n",
       " 'preprocessor__subject__min_df': 0.005}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (4) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtry_different_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid_search\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m, in \u001b[0;36mtry_different_models\u001b[1;34m(models)\u001b[0m\n\u001b[0;32m     24\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     25\u001b[0m     y_pred_on_train \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m---> 27\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_on_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_on_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape of dataset: \u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\pandas\\core\\series.py:461\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    459\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n\u001b[1;32m--> 461\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[1;32m~\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (4) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "try_different_models(\n",
    "    [\n",
    "        ('grid_search', grid_search.best_estimator_)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmail_organizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
