{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mails_df = pd.read_csv(\"../data/training_data.csv\", sep='~', index_col=0)\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
    "mails_df = pd.DataFrame(imputer.fit_transform(mails_df), columns=mails_df.columns)\n",
    "# mails_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    processed_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def preprocess_sender(address):\n",
    "    address_lst = address.lower().split('@')\n",
    "    address_lst[1] = re.sub('[.]ac|[.]in|[.]com', '', address_lst[1])\n",
    "    address_lst[1] = re.sub('[.]', ' ', address_lst[1])\n",
    "    address_lst[0] = re.sub('[._]', '', address_lst[0])\n",
    "    return ' '.join(address_lst)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('subject', TfidfVectorizer(preprocessor=preprocess_text, min_df=0.01), 'subject'),\n",
    "    ('body', TfidfVectorizer(preprocessor=preprocess_text, max_df=0.8, min_df=0.01), 'body'),\n",
    "    ('sender', TfidfVectorizer(preprocessor=preprocess_sender), 'sender')\n",
    "], remainder='drop')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('svd', TruncatedSVD(n_components=500))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "\n",
    "with open('../data/label_dict.json', 'r') as file:\n",
    "    all_labels = json.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:895: UserWarning: unknown class(es) ['CATEGORY_FORUMS', 'CATEGORY_PERSONAL', 'CATEGORY_PROMOTIONS', 'CATEGORY_UPDATES', 'IMPORTANT', 'INBOX', 'SENT', 'STARRED', 'UNREAD'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "label_list = [key for key in all_labels.keys() if re.match('Label_[0-9]', key)]\n",
    "mlb = MultiLabelBinarizer(classes=label_list)\n",
    "labels_array = [list(st.split(',')) for st in mails_df['labels']]\n",
    "mlb.fit(label_list)\n",
    "labels = mlb.transform(labels_array)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "feature_matrix = pipeline.fit_transform(mails_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "<1198x1861 sparse matrix of type '<class 'numpy.float64'>'\n\twith 75856 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1198, 1861) (1198, 21)\n"
     ]
    }
   ],
   "source": [
    "X = feature_matrix\n",
    "y = labels\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 1861) \n",
      "\n",
      "(360, 1861) \n",
      "\n",
      "(838, 21) \n",
      "\n",
      "(360, 21) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lst = [X_train, X_test, y_train, y_test]\n",
    "for i in lst:\n",
    "    print(i.shape, '\\n')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree\n",
      "0.7666666666666667 \t 0.9988066825775657\n",
      "ETree\n",
      "0.7055555555555556 \t 0.9988066825775657\n",
      "ETrees\n",
      "0.8277777777777777 \t 0.9988066825775657\n",
      "RF\n",
      "0.8138888888888889 \t 0.9988066825775657\n",
      "KNN\n",
      "0.8194444444444444 \t 0.8365155131264916\n",
      "SVM\n",
      "0.8388888888888889 \t 0.9164677804295943\n",
      "XGB\n",
      "0.825 \t 0.9988066825775657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "def try_different_models(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = [\n",
    "        ('DTree', DecisionTreeClassifier()),\n",
    "        ('ETree', ExtraTreeClassifier()),\n",
    "        ('ETrees', ExtraTreesClassifier()),\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('SVM', MultiOutputClassifier(SVC())),\n",
    "        ('XGB', XGBClassifier())\n",
    "    ]\n",
    "\n",
    "    for name, model in models:\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_validation = clf.predict(X_train)\n",
    "        print(name)\n",
    "        print(accuracy_score(y_test, y_pred), '\\t', accuracy_score(y_train, y_validation))\n",
    "\n",
    "\n",
    "try_different_models(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN and SVM are reliable classifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.73        14\n",
      "           1       0.50      0.33      0.40        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.96      0.81      0.88        57\n",
      "           4       0.97      0.88      0.92        32\n",
      "           5       1.00      0.88      0.93         8\n",
      "           6       0.92      1.00      0.96        11\n",
      "           7       0.75      1.00      0.86         3\n",
      "           8       0.67      0.29      0.40         7\n",
      "           9       0.74      0.91      0.82        22\n",
      "          10       1.00      0.33      0.50        12\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.88      1.00      0.93         7\n",
      "          13       0.83      0.36      0.50        14\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00        13\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         7\n",
      "          19       0.83      1.00      0.91         5\n",
      "          20       0.76      0.83      0.79        23\n",
      "\n",
      "   micro avg       0.87      0.77      0.82       261\n",
      "   macro avg       0.79      0.73      0.74       261\n",
      "weighted avg       0.86      0.77      0.80       261\n",
      " samples avg       0.37      0.36      0.36       261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        14\n",
      "           1       0.83      0.42      0.56        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       1.00      0.81      0.89        57\n",
      "           4       1.00      0.88      0.93        32\n",
      "           5       1.00      0.88      0.93         8\n",
      "           6       1.00      1.00      1.00        11\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      0.43      0.60         7\n",
      "           9       0.68      0.86      0.76        22\n",
      "          10       1.00      0.33      0.50        12\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.88      1.00      0.93         7\n",
      "          13       1.00      0.36      0.53        14\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00        13\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         7\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       1.00      0.78      0.88        23\n",
      "\n",
      "   micro avg       0.95      0.76      0.85       261\n",
      "   macro avg       0.83      0.68      0.73       261\n",
      "weighted avg       0.94      0.76      0.82       261\n",
      " samples avg       0.37      0.35      0.35       261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('SVM', MultiOutputClassifier(SVC()))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_validation = clf.predict(X_train)\n",
    "    print(name)\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmail_organizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
