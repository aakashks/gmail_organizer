{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is the main notebook.\n",
    "the supervised ML part of the project is all here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "mails_df = pd.read_csv(\"../data/training_data.csv\", sep='~', index_col=0)\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
    "mails_df = pd.DataFrame(imputer.fit_transform(mails_df), columns=mails_df.columns)\n",
    "mails_df.iloc[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    processed_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def preprocess_sender(address):\n",
    "    address_lst = address.lower().split('@')\n",
    "    address_lst[1] = re.sub('[.]ac|[.]in|[.]com', '', address_lst[1])\n",
    "    address_lst[1] = re.sub('[.]', ' ', address_lst[1])\n",
    "    address_lst[0] = re.sub('[._]', '', address_lst[0])\n",
    "    return ' '.join(address_lst)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('subject', TfidfVectorizer(preprocessor=preprocess_text, min_df=0.01), 'subject'),\n",
    "    ('body', TfidfVectorizer(preprocessor=preprocess_text, max_df=0.8, min_df=0.01), 'body'),\n",
    "    ('sender', TfidfVectorizer(preprocessor=preprocess_sender), 'sender')\n",
    "], remainder='drop')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('svd', TruncatedSVD(n_components=500))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "\n",
    "with open('../data/label_dict.json', 'r') as file:\n",
    "    all_labels = json.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encoding labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msing\\.conda\\envs\\gmail_organizer\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:895: UserWarning: unknown class(es) ['CATEGORY_FORUMS', 'CATEGORY_PERSONAL', 'CATEGORY_PROMOTIONS', 'CATEGORY_UPDATES', 'IMPORTANT', 'INBOX', 'SENT', 'STARRED', 'UNREAD'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "label_list = [key for key in all_labels.keys() if re.match('Label_[0-9]', key)]\n",
    "mlb = MultiLabelBinarizer(classes=label_list)\n",
    "labels_array = [list(st.split(',')) for st in mails_df['labels']]\n",
    "mlb.fit(label_list)\n",
    "labels = mlb.transform(labels_array)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "feature_matrix = pipeline.fit_transform(mails_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "<1198x1861 sparse matrix of type '<class 'numpy.float64'>'\n\twith 75856 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1198, 1861) (1198, 21)\n"
     ]
    }
   ],
   "source": [
    "X = feature_matrix\n",
    "y = labels\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 1861) \n",
      "\n",
      "(360, 1861) \n",
      "\n",
      "(838, 21) \n",
      "\n",
      "(360, 21) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lst = [X_train, X_test, y_train, y_test]\n",
    "for i in lst:\n",
    "    print(i.shape, '\\n')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### My main metric for evaluation is precision_score. It is best suited for the multi-output classification. Its details as mentioned in its documentation\n",
    "\n",
    "\"\"\"\n",
    "Compute the precision.\n",
    "\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The best value is 1 and the worst value is 0.\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "as sizes of all labels are different, and they are very imbalanced, so I've used average='weighted'\n",
    "\"\"\"\n",
    "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        test_accuracy  train_accuracy  precision_score\n",
      "DTree        0.797222        0.998807         0.828804\n",
      "ETree        0.700000        0.998807         0.702509\n",
      "ETrees       0.833333        0.998807         0.927859\n",
      "RF           0.825000        0.998807         0.946676\n",
      "KNN          0.819444        0.836516         0.857782\n",
      "SVM          0.838889        0.916468         0.942734\n",
      "XGB          0.825000        0.998807         0.911858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "def try_different_models(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = [\n",
    "        ('DTree', DecisionTreeClassifier()),\n",
    "        ('ETree', ExtraTreeClassifier()),\n",
    "        ('ETrees', ExtraTreesClassifier()),\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('SVM', MultiOutputClassifier(SVC())),\n",
    "        ('XGB', XGBClassifier())\n",
    "    ]\n",
    "    dfs = []\n",
    "    for name, model in models:\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_validation = clf.predict(X_train)\n",
    "\n",
    "        score = pd.Series(\n",
    "            [accuracy_score(y_test, y_pred), accuracy_score(y_train, y_validation), precision_score(y_test, y_pred, average='weighted', zero_division=0)], index=['test_accuracy', 'train_accuracy', 'precision_score'], name=name\n",
    "        )\n",
    "        dfs.append(score)\n",
    "    print(pd.DataFrame(dfs))\n",
    "\n",
    "try_different_models(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM seems to be the best classifier among these"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "SVM\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmail_organizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
