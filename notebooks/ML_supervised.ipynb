{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is the main notebook.\n",
    "the supervised ML part of the project is all here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mails_df = pd.read_csv(\"../data/training_data.csv\", sep='~', index_col=0)\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
    "mails_df = pd.DataFrame(imputer.fit_transform(mails_df), columns=mails_df.columns)\n",
    "mails_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    processed_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def preprocess_sender(address):\n",
    "    address_lst = address.lower().split('@')\n",
    "    address_lst[1] = re.sub('[.]ac|[.]in|[.]com', '', address_lst[1])\n",
    "    address_lst[1] = re.sub('[.]', ' ', address_lst[1])\n",
    "    address_lst[0] = re.sub('[._]', '', address_lst[0])\n",
    "    return ' '.join(address_lst)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('subject', TfidfVectorizer(preprocessor=preprocess_text, max_df=0.9, min_df=0.005), 'subject'),\n",
    "    ('body', TfidfVectorizer(preprocessor=preprocess_text, max_df=0.8, min_df=0.01), 'body'),\n",
    "    ('sender', TfidfVectorizer(preprocessor=preprocess_sender), 'sender')\n",
    "],\n",
    "    # transformer_weights={\n",
    "    #     'subject': 2,\n",
    "    #     'body': 1,\n",
    "    #     'sender': 4\n",
    "    # },\n",
    "    remainder='drop')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('svd', TruncatedSVD(n_components=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "\n",
    "with open('../data/label_dict.json', 'r') as file:\n",
    "    all_labels = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_list = [key for key in all_labels.keys() if re.match('Label_[0-9]', key)]\n",
    "mlb = MultiLabelBinarizer(classes=label_list)\n",
    "labels_array = [list(st.split(',')) for st in mails_df['labels']]\n",
    "mlb.fit(label_list)\n",
    "labels = mlb.transform(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix = pipeline.fit_transform(mails_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1198x2106 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 81480 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1198, 2106) (1198, 21)\n"
     ]
    }
   ],
   "source": [
    "X = feature_matrix\n",
    "y = labels\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 2106) \n",
      "\n",
      "(360, 2106) \n",
      "\n",
      "(838, 21) \n",
      "\n",
      "(360, 21) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lst = [X_train, X_test, y_train, y_test]\n",
    "for i in lst:\n",
    "    print(i.shape, '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "My main metric for evaluation is precision_score. It is best suited for the multi-output classification. Its details as mentioned in its documentation\n",
    "\n",
    "\n",
    "> Compute the precision.\n",
    "> The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    ">The best value is 1 and the worst value is 0.\n",
    "\n",
    "as sizes of all labels are different, and they are very imbalanced, so I've used average='weighted'\n",
    "\n",
    "> Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1198, 2106) (1198, 21)\n",
      "        test_accuracy  train_accuracy  precision_score  precision_score_train\n",
      "DTree        0.794444        0.998807         0.804978               1.000000\n",
      "ETree        0.705556        0.998807         0.673021               1.000000\n",
      "ETrees       0.838889        0.998807         0.940630               1.000000\n",
      "RF           0.819444        0.998807         0.938497               1.000000\n",
      "KNN          0.800000        0.834129         0.849182               0.887626\n",
      "SVM          0.822222        0.921241         0.937338               0.991534\n",
      "XGB          0.841667        0.997613         0.928790               1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "def try_different_models(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = [\n",
    "        ('DTree', DecisionTreeClassifier()),\n",
    "        ('ETree', ExtraTreeClassifier()),\n",
    "        ('ETrees', ExtraTreesClassifier()),\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('SVM', MultiOutputClassifier(SVC())),\n",
    "        ('XGB', XGBClassifier())\n",
    "    ]\n",
    "    dfs = []\n",
    "    for name, model in models:\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "\n",
    "        score = pd.Series(\n",
    "            [\n",
    "                accuracy_score(y_test, y_pred), accuracy_score(y_train, y_pred_train), \n",
    "                precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                precision_score(y_train, y_pred_train, average='weighted', zero_division=0)\n",
    "            ], \n",
    "            index=['test_accuracy', 'train_accuracy', 'precision_score', 'precision_score_train'], \n",
    "            name=name\n",
    "        )\n",
    "        dfs.append(score)\n",
    "        \n",
    "    print(X.shape, y.shape)\n",
    "    print(pd.DataFrame(dfs))\n",
    "\n",
    "\n",
    "try_different_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "SVM seems to be the best classifier among these"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmail_organizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
